{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95bd6198-8382-4969-aafb-4097773ca274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: C:\\Users\\Adan\\Downloads\\motor_second.csv\n",
      "Cleaned Columns: ['model', 'tahun', 'harga', 'transmisi', 'odometer', 'jenis', 'pajak', 'konsumsibbm', 'mesin']\n",
      "\n",
      "Detected numeric columns: ['tahun', 'odometer', 'pajak', 'konsumsibbm', 'mesin']\n",
      "Detected categorical columns: ['model', 'transmisi', 'jenis']\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating...\n",
      "MAE: 844.06\n",
      "RMSE: 1368807.70\n",
      "R2: 0.903\n",
      "\n",
      "Running 5-fold Cross Validation (MAE)...\n",
      "CV MAE: mean=1241.38, std=251.35\n",
      "\n",
      "Model saved successfully to model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# ------------- USER SETTINGS -------------\n",
    "CSV_PATH = r\"C:\\Users\\Adan\\Downloads\\motor_second.csv\"\n",
    "TARGET_COLUMN = \"harga\"\n",
    "MODEL_OUTPUT = \"model.pkl\"\n",
    "RANDOM_STATE = 42\n",
    "# -----------------------------------------\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Normalisasi nama kolom\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.replace(\" \", \"\")\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    print(\"Cleaned Columns:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "def auto_detect_columns(df):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "    return numeric_cols, categorical_cols\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data:\", CSV_PATH)\n",
    "    df = load_data(CSV_PATH)\n",
    "\n",
    "    if TARGET_COLUMN not in df.columns:\n",
    "        print(f\"ERROR: target column '{TARGET_COLUMN}' tidak ditemukan!\")\n",
    "        print(\"Kolom tersedia:\", df.columns.tolist())\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Drop rows yang targetnya kosong\n",
    "    df = df.dropna(subset=[TARGET_COLUMN]).copy()\n",
    "\n",
    "    X = df.drop(columns=[TARGET_COLUMN])\n",
    "    y = df[TARGET_COLUMN].astype(float)\n",
    "\n",
    "    numeric_cols, categorical_cols = auto_detect_columns(X)\n",
    "\n",
    "    print(\"\\nDetected numeric columns:\", numeric_cols)\n",
    "    print(\"Detected categorical columns:\", categorical_cols)\n",
    "\n",
    "    pipeline = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining model...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2: {r2:.3f}\")\n",
    "\n",
    "    print(\"\\nRunning 5-fold Cross Validation (MAE)...\")\n",
    "    cv_scores = -1 * cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"CV MAE: mean={cv_scores.mean():.2f}, std={cv_scores.std():.2f}\")\n",
    "\n",
    "    # Residual stats\n",
    "    train_pred = pipeline.predict(X_train)\n",
    "    residuals = y_train - train_pred\n",
    "\n",
    "    metadata = {\n",
    "        \"target\": TARGET_COLUMN,\n",
    "        \"numeric_cols\": numeric_cols,\n",
    "        \"categorical_cols\": categorical_cols,\n",
    "        \"residual_mean\": float(residuals.mean()),\n",
    "        \"residual_std\": float(residuals.std()),\n",
    "        \"r2\": float(r2)\n",
    "    }\n",
    "\n",
    "    joblib.dump(\n",
    "        {\n",
    "            \"pipeline\": pipeline,\n",
    "            \"metadata\": metadata\n",
    "        },\n",
    "        MODEL_OUTPUT\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel saved successfully to {MODEL_OUTPUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc3b660-656b-4d91-b3df-80d799382f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Adan\\\\benerProject\\\\Harga-Motor-Al'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "getData=os.getcwd()\n",
    "getData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
